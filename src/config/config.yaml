# Shuttle-Sense-VLM Unified Configuration
# Combines API endpoints, models, prompts, and few-shot settings

# ============================================================================
# Models Configuration
# ============================================================================
models:
  qwen-vl-max:
    name: "qwen-vl-max-latest"  # Model name as recognized by the API
    description: "Qwen VL Max model via DashScope"
    api_type: "dashscope"  # SDK type: "dashscope" or "openai"
    base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
    api_key_env: "DASHSCOPE_API_KEY"  # Environment variable name for API key

  qwen-vl-plus:
    name: "qwen3-vl-plus"
    description: "Qwen VL Plus model via DashScope"
    api_type: "dashscope"
    base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
    api_key_env: "DASHSCOPE_API_KEY"

  qwen-vl-flash:
    name: "qwen-vl-flash"
    description: "Qwen VL Flash model via DashScope"
    api_type: "dashscope"
    base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
    api_key_env: "DASHSCOPE_API_KEY"

  qwen3-vl-8b-local:
    name: "Qwen/Qwen3-VL-8B-Instruct"
    description: "Local Qwen VL model via vLLM"
    api_type: "openai"  # OpenAI-compatible API
    base_url: "http://localhost:8000/v1"
    api_key_env: "OPENAI_API_KEY"

  gpt4-vision:
    name: "gpt-4-vision-preview"
    description: "GPT-4 Vision via OpenAI API"
    api_type: "openai"
    base_url: "https://api.openai.com/v1"
    api_key_env: "OPENAI_API_KEY"

  qwen3-vl-32b-local:
    name: "Qwen3-VL-30B-A3B-Thinking"
    description: "Local Qwen VL 30B A3B Thinking model via vLLM"
    api_type: "openai"
    base_url: "http://ec2-44-249-79-188.us-west-2.compute.amazonaws.com/v1"
    api_key_env: "OPENAI_API_KEY"

# Active Model Selection
active_model: "qwen3-vl-8b-local"
# active_model: "qwen3-vl-32b-local"

# ============================================================================
# Video Processing Configuration
# ============================================================================
video_frames:
  max_frames: 8  # Maximum number of frames to extract per video segment
  frame_size: [1536, 1536]  # Frame size [width, height]

video_segmentation:
  segment_duration: 2.0  # Duration of each video segment in seconds
  overlap_duration: 1.0  # Overlap between consecutive segments in seconds
  max_segments: null     # Maximum number of segments to process (null = process all segments)

# ============================================================================
# Inference Parameters
# ============================================================================
inference:
  batch_size: 4  # Number of segments to process in parallel
  max_new_tokens: 50  # Maximum number of tokens to generate
  temperature: 0.1  # Temperature for sampling (lower = more deterministic)
  top_p: 0.8  # Top-p sampling parameter
  do_sample: false  # Whether to use sampling

# ============================================================================
# Few-shot Learning Configuration
# ============================================================================
few_shot:
  enabled: true # Enable few-shot learning mode
  examples_dir: "few_shot_examples"  # Directory for storing example frames

  # List of example IDs to use for few-shot learning
  # Options:
  #   - [1, 2, 3, 4, 5, 6]: Use specific examples (default)
  #   - []: Empty list - use ALL available examples from annotations file
  #   - null: Use ALL available examples from annotations file
  example_ids: [1, 2, 3, 4]

  example_frames_per_video: 8  # Number of frames to extract per example video
  save_message_images: true  # Save all images from messages for debugging
  saved_images_dir: "debug_message_images"  # Directory to save message images

# ============================================================================
# Prompts Configuration
# ============================================================================
prompts:
  # Serve detection prompts
  serve:
    has_serve: "这段羽毛球视频中是否包含发球动作？如果包含请给出发球动作所在的时间区间，输出格式为：{\"action_type\": \"serve\", \"start_time\": {start_time}, \"end_time\": {end_time}}，如果不包含请回答没有发球动作，输出格式为：{\"action_type\": \"no_serve\"}，不要输出任何其他内容。"
    serve_type: "描述这段羽毛球视频中的发球类型：高远球发球、平快球发球、网前球发球、反手发球或其他"

  # Rally analysis prompts
  rally:
    has_rally: "这段羽毛球视频中是否有正在进行的回合？请回答：有回合 或 无回合"
    action_type: "描述这段羽毛球视频中的主要动作类型：发球、接发球、对拉、杀球、吊球、网前球或其他"
    rally_intensity: "评估这段羽毛球回合的激烈程度：低、中、高"
    player_activity: "这段视频中羽毛球选手的活动状态：活跃比赛、准备阶段、休息或无活动"

  # General prompts
  general:
    describe_content: "详细描述这段羽毛球视频中的内容"
    count_players: "这段视频中有多少名羽毛球选手？"
    court_position: "描述羽毛球选手在场地上的位置：前场、中场、后场"

  # Prompt templates for dynamic generation
  templates:
    yes_no_question: "这段羽毛球视频中是否{action}？请回答：{yes_answer} 或 {no_answer}"
    describe_action: "描述这段羽毛球视频中的{action_category}：{action_options}"
    evaluate_level: "评估这段羽毛球{aspect}的{metric}：{levels}"

# ============================================================================
# System Prompts for Few-shot Learning
# ============================================================================
system_prompts:
  serve_detection: |
    你是一名专业的羽毛球动作识别专家。
    你的任务是分析羽毛球视频片段，判断其中是否包含发球动作。

    【发球定义】
    羽毛球发球是指发球员在发球区内，以一个连续向前的挥拍动作，用球拍击打羽毛球底部，使球飞过球网进入对方发球区的动作。

    【关键特征】
    - 站位：靠近中线，身体正对球网，重心略低。
    - 握拍：采用反手握拍，拇指靠在拍柄宽面上。
    - 托球：非持拍手将球托在拍面前方，球大约与腰部同高。
    - 引拍：持拍手肘略抬起，拍面略向下倾。
    - 击球：轻轻用手指和手腕向前推球，动作短、小、快。
    - 路线：球过网后落点尽可能贴近前发球线，压低球网。
    - 收拍与准备：球出手后立即回到中后场准备位置。
    - 对手臂的要求
      - 手臂不能把击球点抬到腰以上：
        - 因为球被击中时必须在腰部以下。
      - 手臂和手腕的姿势必须保证 “拍头低于持拍手”：
        - 任何导致“拍头高于持拍手”的手臂抬高与甩动，都是潜在违例风险。
      - 手臂挥动方向必须包含明显的“由下向上成分”：
        - 不能做近似水平或向下砍的击球动作。
      - 手臂的挥动必须一气呵成，不得中途停顿或假动作：
        - 手臂前送一旦开始，中间不能再停顿再发力。
      - 托球那只手的手臂要把球放在身体前方，并自然放球，不得向上抛球：
        - 手臂动作太大、明显抛球，会被判违例。

    【分析要求】
    - 仔细观察视频中的每一帧
    - 识别发球的准备、挥拍和击球动作
    - 基于典型特征做出准确判断
    - 请严格按照发球定义和关键特征进行分析，不要进行任何主观判断
    - 输入的图像为视频帧，每秒4帧，请根据视频帧分析发球动作
    - 请仔细思考后给出答案，不要轻易给出答案

# ============================================================================
# Annotations Configuration
# ============================================================================
annotations_path: "data/annotations_exp.json"
